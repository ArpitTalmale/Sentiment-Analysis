{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e534ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Library\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import contractions\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer ,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f3b6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting Data\n",
    "\n",
    "data = pd.read_csv(\"Train.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4329aa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b31a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of the data\n",
    "\n",
    "def remove_spaces(data):\n",
    "    clean_text = data.replace('\\\\n',' ').replace('\\t',' ').replace('\\\\',' ')\n",
    "    return clean_text\n",
    "\n",
    "def expand_text(data):\n",
    "    expanded_text = contractions.fix(data)\n",
    "    return expanded_text\n",
    "    \n",
    "def handling_accented(data):\n",
    "    fixed_text = unidecode(data)\n",
    "    return fixed_text\n",
    "\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "stopword_list.remove('nor')\n",
    "\n",
    "def clean_data(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    clean_text = [word.lower() for word in tokens if (word not in punctuation) and (word.lower() not in stopword_list) and (len(word)>2) and (word.isalpha())]\n",
    "    return clean_text\n",
    "\n",
    "def autocorrection(data):\n",
    "    spell = Speller(lang='en')\n",
    "    corrected_text= spell(data)\n",
    "    return corrected_text\n",
    "\n",
    "def lemmatization(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final_data=[]\n",
    "    for word in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        final_data.append(lemmatized_word)\n",
    "    return ' '.join(final_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f62b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data.text,data.label,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d19a0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_train = x_train.apply(remove_spaces)\n",
    "clean_text_test = x_test.apply(remove_spaces)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(expand_text)\n",
    "clean_text_text = clean_text_test.apply(expand_text)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(handling_accented)\n",
    "clean_text_test = clean_text_test.apply(handling_accented)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(clean_data)\n",
    "clean_text_test = clean_text_test.apply(clean_data)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(lemmatization)\n",
    "clean_text_test = clean_text_test.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb81ee90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26898    fifth grade language art teacher read book stu...\n",
       "27635    low budget brit pop melodrama focus girl want ...\n",
       "3036     well watched movie little year ago pulled dust...\n",
       "5604     would almost give however confusing part well ...\n",
       "36111    full length feature film world bridge found fi...\n",
       "                               ...                        \n",
       "6265     movie one worst movie ever seen life waste tim...\n",
       "11284    movie inspiring anyone tough jam whether finan...\n",
       "38158    east side story documentary musical comedy sta...\n",
       "860      one boot one point doctor assistant refers wor...\n",
       "15795    movie horrible lighting terrible camera moveme...\n",
       "Name: text, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4556a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# ngrams\n",
    "\n",
    "from nltk.util import ngrams\n",
    "def splitting_dataframe(data):\n",
    "    tokens = data.split()\n",
    "    return tokens\n",
    "data = clean_text_test.apply(splitting_dataframe)\n",
    "\n",
    "def ngram_list(data,ngram_range):\n",
    "    ngram = ngrams(data,ngram_range) \n",
    "    ngram_list1 = []\n",
    "    for ngram1 in ngram:\n",
    "        ngram_list1.append(' '.join(ngram1))\n",
    "    return ngram_list1    \n",
    "\n",
    "unigrams = data.apply(lambda x : ngram_list(x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23bc0fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central, theme, movie, seems, confusion, rela...\n",
       "16298    [excellent, example, cowboy, noir, called, une...\n",
       "28505    [ending, made, heart, jump, throat, proceeded,...\n",
       "6689     [chosen, one, appreciate, quality, story, char...\n",
       "26893    [really, funny, film, especially, second, thir...\n",
       "                               ...                        \n",
       "29415    [film, came, gift, offering, blue, unlike, rev...\n",
       "11359    [first, started, watching, movie, looking, kin...\n",
       "575      [big, mark, music, neil, young, glowing, prais...\n",
       "17398    [watching, lady, ermine, wondering, betty, gra...\n",
       "4189     [crappy, miserably, acted, movie, based, subli...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7f39be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central theme, theme movie, movie seems, seem...\n",
       "16298    [excellent example, example cowboy, cowboy noi...\n",
       "28505    [ending made, made heart, heart jump, jump thr...\n",
       "6689     [chosen one, one appreciate, appreciate qualit...\n",
       "26893    [really funny, funny film, film especially, es...\n",
       "                               ...                        \n",
       "29415    [film came, came gift, gift offering, offering...\n",
       "11359    [first started, started watching, watching mov...\n",
       "575      [big mark, mark music, music neil, neil young,...\n",
       "17398    [watching lady, lady ermine, ermine wondering,...\n",
       "4189     [crappy miserably, miserably acted, acted movi...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bigrams = data.apply(lambda x : ngram_list(x,2))\n",
    "Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d972449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central theme movie, theme movie seems, movie...\n",
       "16298    [excellent example cowboy, example cowboy noir...\n",
       "28505    [ending made heart, made heart jump, heart jum...\n",
       "6689     [chosen one appreciate, one appreciate quality...\n",
       "26893    [really funny film, funny film especially, fil...\n",
       "                               ...                        \n",
       "29415    [film came gift, came gift offering, gift offe...\n",
       "11359    [first started watching, started watching movi...\n",
       "575      [big mark music, mark music neil, music neil y...\n",
       "17398    [watching lady ermine, lady ermine wondering, ...\n",
       "4189     [crappy miserably acted, miserably acted movie...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trigrams = data.apply(lambda x : ngram_list(x,3))\n",
    "Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d6528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Count Vectorizer\n",
    "\n",
    "count = CountVectorizer(max_df=0.95,max_features=1000)\n",
    "count_val_train = count.fit_transform(clean_text_train)\n",
    "count_val_test = count.transform(clean_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33ce85ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able  absolutely  accent  across  act  acted  acting  action  \\\n",
       "0            0     0           0       0       0    0      0       2       0   \n",
       "1            0     0           0       0       0    0      0       0       0   \n",
       "2            0     0           0       0       0    0      0       0       0   \n",
       "3            0     0           0       1       0    0      0       0       0   \n",
       "4            0     0           2       0       0    0      0       0       0   \n",
       "...        ...   ...         ...     ...     ...  ...    ...     ...     ...   \n",
       "29995        0     0           0       0       0    1      0       1       0   \n",
       "29996        0     0           0       0       0    0      0       0       0   \n",
       "29997        0     0           0       0       0    0      0       0       0   \n",
       "29998        0     0           0       0       0    0      0       1       0   \n",
       "29999        0     0           0       0       0    0      0       1       0   \n",
       "\n",
       "       actor  ...  wrong  wrote  yeah  year  yes  yet  york  young  younger  \\\n",
       "0          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "1          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "2          0  ...      0      0     0     1    0    0     0      0        0   \n",
       "3          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "4          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "...      ...  ...    ...    ...   ...   ...  ...  ...   ...    ...      ...   \n",
       "29995      0  ...      0      0     0     0    0    0     0      0        0   \n",
       "29996      0  ...      0      0     0     0    0    0     0      0        0   \n",
       "29997      0  ...      0      0     0     1    0    0     0      0        0   \n",
       "29998      0  ...      1      0     0     0    0    0     0      0        0   \n",
       "29999      0  ...      0      1     0     1    0    0     0      0        0   \n",
       "\n",
       "       zombie  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "29995       0  \n",
       "29996       0  \n",
       "29997       0  \n",
       "29998       0  \n",
       "29999       0  \n",
       "\n",
       "[30000 rows x 1000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_val_train.A,columns=count.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf3304d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.11"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Building By using Navie Bayes Classifier\n",
    "\n",
    "\n",
    "count_mnb = MultinomialNB()\n",
    "count_mnb.fit(count_val_train.A,y_train)\n",
    "predict_count = count_mnb.predict(count_val_test.A)\n",
    "accuracy_count = accuracy_score(y_test,predict_count)*100\n",
    "accuracy_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eed6ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.95,max_features=1000)\n",
    "tfidf_train = tfidf.fit_transform(clean_text_train)\n",
    "tfidf_test = tfidf.transform(clean_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78351e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.189091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able  absolutely    accent  across       act  acted    acting  \\\n",
       "0          0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.182468   \n",
       "1          0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "2          0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "3          0.0   0.0    0.000000  0.137926     0.0  0.000000    0.0  0.000000   \n",
       "4          0.0   0.0    0.321531  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "...        ...   ...         ...       ...     ...       ...    ...       ...   \n",
       "29995      0.0   0.0    0.000000  0.000000     0.0  0.135608    0.0  0.088057   \n",
       "29996      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "29997      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "29998      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.050570   \n",
       "29999      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.097604   \n",
       "\n",
       "       action  actor  ...    wrong     wrote  yeah      year  yes  yet  york  \\\n",
       "0         0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "1         0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "2         0.0    0.0  ...  0.00000  0.000000   0.0  0.055835  0.0  0.0   0.0   \n",
       "3         0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "4         0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "...       ...    ...  ...      ...       ...   ...       ...  ...  ...   ...   \n",
       "29995     0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "29996     0.0    0.0  ...  0.00000  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "29997     0.0    0.0  ...  0.00000  0.000000   0.0  0.074143  0.0  0.0   0.0   \n",
       "29998     0.0    0.0  ...  0.07508  0.000000   0.0  0.000000  0.0  0.0   0.0   \n",
       "29999     0.0    0.0  ...  0.00000  0.189091   0.0  0.102630  0.0  0.0   0.0   \n",
       "\n",
       "       young  younger  zombie  \n",
       "0        0.0      0.0     0.0  \n",
       "1        0.0      0.0     0.0  \n",
       "2        0.0      0.0     0.0  \n",
       "3        0.0      0.0     0.0  \n",
       "4        0.0      0.0     0.0  \n",
       "...      ...      ...     ...  \n",
       "29995    0.0      0.0     0.0  \n",
       "29996    0.0      0.0     0.0  \n",
       "29997    0.0      0.0     0.0  \n",
       "29998    0.0      0.0     0.0  \n",
       "29999    0.0      0.0     0.0  \n",
       "\n",
       "[30000 rows x 1000 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_train.A,columns= tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cd6c1571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.74000000000001"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mnb = MultinomialNB()\n",
    "tfidf_mnb.fit(tfidf_train.A,y_train)\n",
    "predict_tfidf = tfidf_mnb.predict(tfidf_test.A)\n",
    "accuracy_tfidf = accuracy_score(y_test,predict_tfidf)*100\n",
    "accuracy_tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
